1. 파일 디스크립터(FD) 한계 해제 — “50k WebSocket/서버”의 필수 전제
왜 중요한가

    WebSocket 1개 = FD 1개(커널의 소켓 FD).

    서버 1대에 5만 연결이면 최소 5만 FD가 필요하고, 로그/파일/내부 파이프까지 고려하면 **여유분 포함 10만+**을 잡는 게 안전.

    리눅스 기본 ulimit -n(per‑process)은 1024, 시스템 전역 fs.file-max도 낮게 잡혀 있으면 병목.


    1. 파일 디스크립터(FD)가 뭐냐면

        **운영체제(OS)**가 "열려 있는 파일, 네트워크 연결"을 구분하기 위해 붙이는 번호표 같은 거예요.

        파일뿐만 아니라 **TCP 연결(WebSocket 포함)**도 다 FD 하나씩 차지해요.

    2. 왜 50k WebSocket에서 문제가 되냐면

        WebSocket 연결 하나당 FD 1개가 필요해요.

        서버 1대에서 5만 명이 동시에 접속하면, 그 순간 FD만 5만 개 이상 필요하죠.

        그런데 **리눅스 기본 제한(ulimit)**은 1024개라서, 그대로 두면 1천명 정도 접속만 돼도 더 이상 연결을 못 받습니다.

    3. 그래서 한계를 풀어줘야 해요

        OS 설정을 바꿔서 최대 FD 수를 10만~수백만 개로 늘립니다.

        ulimit -n 값, /etc/security/limits.conf, systemd 서비스 설정, 그리고 fs.file-max(커널 전체 제한)까지 맞춰줘야 진짜 적용돼요.

    4. 왜 필수 전제냐면

        이걸 안 하면 아무리 서버 스펙이 좋아도 동시 연결 수가 제한돼서 서비스 설계 목표(50k 동접/서버)를 달성 못 합니다.

        즉, 성능 튜닝 이전에 기본 용량 확보 작업이라고 보면 돼요.


    5. 왜 10만이 안전한가 (간단 산식)

        FD는 연결 1개당 1개(WebSocket=TCP 소켓=FD 1개).

        우리가 TCP 버퍼를 8KB/8KB로 낮췄다면, 메모리 대략:

        버퍼 메모리: 8KB×2×50,000 ≈ ~0.76GB

        TCP 제어블록/큐/커널 오버헤드까지 합치면 1.52GB 수준(대략치)

        서버 RAM이 16GB 이상이면 충분한 여유가 남습니다. (애플리케이션/캐시/페이지캐시 포함)



2. TCP 소켓 버퍼 128KB → 8KB — “작은 메시지 대량 동접”에 맞춘 메모리 절감


    TCP 버퍼를 8KB로 줄이는 이유는 동시 접속 수가 많을 때 커널 메모리를 크게 절약하기 위해서입니다.

        1. 기본 개념

            TCP 소켓에는 수신 버퍼(RX), **송신 버퍼(TX)**가 있습니다.

            리눅스 기본값은 보통 128KB 정도로 설정돼 있습니다.

            즉, 연결 1개당 128KB × 2 = 256KB가 커널 메모리에서 고정 또는 준고정으로 잡힙니다.

        2. 동시접속이 많으면 생기는 문제

            예를 들어, 서버 1대에 50,000개의 WebSocket 연결이 유지된다면:

            기본값(128KB 버퍼)일 경우
            50,000 × 256KB ≈ 12.2GB
            → 커널 메모리만 12GB 이상 잡아먹음 (애플리케이션·캐시 메모리 여유가 줄어듦)

            버퍼를 8KB로 줄이면
            50,000 × (8KB × 2) ≈ 0.76GB
            → 16배 절약

        3. 왜 8KB로도 괜찮은가

            실시간 시청자 수 집계는 메시지 크기가 매우 작음
            (보통 수십~수백 바이트, 예: {"count":12345})

            큰 파일 전송이나 영상 스트리밍처럼 대용량 데이터를 밀어 넣는 패턴이 아님

            따라서 128KB처럼 큰 윈도우를 가질 필요가 없음

        4. 장점

            RAM 절감 → 같은 서버에서 더 많은 연결을 처리 가능

            메모리 부족으로 인한 OOM(Out-Of-Memory) 위험 감소

            커널 메모리 확보로 다른 캐시·네트워크 버퍼 사용 여유 확보




    왜 효과가 큰가

        연결 수(N)가 크면 (RX버퍼 + TX버퍼) × N이 커널 메모리로 고정(또는 준고정) 잡힘.

        실시간 시청자수는 수십~수백 바이트의 신호(입장/퇴장/카운트 푸시)가 대부분 → 큰 윈도우가 불필요.

    대략 계산

        기본 128KB 가정 시: 128KB×2(양방향)×50,000 ≈ 12.2 GB

        8KB로 내리면: 8KB×2×50,000 ≈ 0.76 GB → ~16배 절감


    애플리케이션 레벨에서도 가능: setsockopt(SO_RCVBUF/SO_SNDBUF)로 8KB 지정.

    실시간 알림류는 **Nagle 비활성화(TCP_NODELAY)**가 일반적. (지연 합치기 대신 즉시 전송)

    리스크 & 가드레일

        모바일/고지연 구간에서 윈도우가 너무 작으면 재전송/ACK 빈도가 늘어 CPU ↗ 가능 → RTT 분포를 보고 8~16KB 범위에서 결정.

        반드시 패킷 드랍률/재전송률, RTT p95/p99를 모니터링해서 검증(A/B)하세요.



    1. **Nagle 비활성화(TCP_NODELAY)**란?

        TCP는 기본적으로 Nagle 알고리즘이라는 걸 켜두는데,
        → 작은 패킷 여러 개를 묶어서(batch) 보낸 뒤 ACK를 기다립니다.
        → 장점: 네트워크 효율↑ (패킷 수 줄임)
        → 단점: 실시간성이 떨어짐 (묶느라 지연 발생)

        실시간 알림이나 WebSocket 시청자 수 변경 알림은 작은 데이터라도 바로 보내야 함.
        그래서 TCP_NODELAY 옵션을 켜서 Nagle 알고리즘을 꺼버림 → “지연 합치기” 대신 즉시 전송.

    2. 윈도우(버퍼) 너무 작을 때의 리스크

        TCP 버퍼 크기(윈도우)를 너무 작게 줄이면:

        데이터 조금 보낼 때도 ACK 왕복이 너무 자주 발생

        재전송도 잦아짐 (특히 모바일, 고지연 네트워크)

        그만큼 CPU 사용량이 증가할 수 있음 (패킷 처리 횟수가 많아짐)

    3. RTT 기반 최적화

        RTT(왕복 시간, Round Trip Time)는 내 서버 ↔ 클라이언트 사이의 왕복 지연 시간.

        RTT가 짧은 국내 환경은 8KB도 충분하지만,
        RTT가 긴 해외나 모바일망은 8KB보다 조금 더 큰 16KB로 버퍼를 잡으면 재전송/ACK 빈도를 줄일 수 있음.

    4. 모니터링 지표

        변경 후에는 꼭 확인해야 함:

        패킷 드랍률

        재전송률

        RTT p95/p99 → 상위 95%, 99% 사용자 지연 시간

        이걸 A/B 테스트(일부 서버에만 적용)로 비교해서, 지표가 악화되지 않으면 전면 적용.

    즉,

        실시간 서비스라 **지연 합치기(Nagle)**는 꺼야 하고,
        버퍼를 너무 줄이면 ACK/재전송이 많아질 수 있으니 RTT 환경에 맞춰 8KB~16KB 범위에서 결정하라는 뜻이에요.








3. MySQL(InnoDB) — “배치 쓰기” 경로를 넓혀 TPS를 끌어올림

    우리 설계는 Redis가 실시간 카운트 처리, MySQL은 5분 주기 배치 업서트가 핵심. 따라서 InnoDB는 “랜덤 단건 갱신 최적화”보다 연속된 배치 쓰기의 지속 처리량을 최대화하는 게 목표.

    핵심 파라미터 가이드(Writer 기준)

        버퍼 풀: 전용 인스턴스면 RAM의 ~70%

            예: 128GB → innodb_buffer_pool_size=90G

            innodb_buffer_pool_instances=8 (대용량일 때 락 경합 완화)

        Redo 로그(총 용량): 8~16GB 권장

        MySQL 8: innodb_redo_log_capacity=8G

        (MySQL 5.7 계열이면 innodb_log_file_size × innodb_log_files_in_group)

        의미: 로그가 작으면 체크포인트가 잦아져 쓰기 TPS가 출렁. 너무 크면 크래시 리커버리 시간↑.

    플러시 정책 (일관성 vs 성능 트레이드오프)

        안전: innodb_flush_log_at_trx_commit=1, sync_binlog=1

        성능(약간의 데이터 손실 허용: 최대 1초): innodb_flush_log_at_trx_commit=2 (+ sync_binlog=0 or 1)

        우리는 배치 업데이트이므로 보통 2가 TPS에 유리.
    
    IO 용량 힌트: innodb_io_capacity=2000, innodb_io_capacity_max=4000 (SSD 기준 시작점)


            1. innodb_io_capacity와 innodb_io_capacity_max가 하는 일

                InnoDB가 백그라운드로 더티 페이지(변경된 페이지)를 디스크로 쓰는 속도를 조절하는 기준 값입니다.

                값이 크면 → 더 빨리 플러시(Flush) → 버퍼 풀에 여유 생김, 체크포인트 지연 완화.
                값이 작으면 → Flush 속도 제한 → 배치 쓰기/대량 변경 시 버퍼 풀이 가득 차고 성능 저하.

            2. 왜 SSD 기준으로 2000 / 4000인가?

                단위: "1초에 처리 가능한 I/O 횟수(ops)"를 의미합니다.

                SSD는 HDD보다 랜덤 I/O 처리량이 훨씬 높기 때문에, InnoDB가 적극적으로 플러시해도 병목이 잘 안 생깁니다.

                MySQL 매뉴얼과 여러 벤치마크 사례에서 엔터프라이즈 SSD 환경은
                innodb_io_capacity = 2000, innodb_io_capacity_max = 4000 정도가 안정적인 시작점이라고 권장합니다.

            3. 수치 근거

                실제 SSD의 IOPS(초당 입출력 횟수) 스펙에서 가져온 값.

                예) 일반 NVMe SSD → 100,000 IOPS 이상

                여기서 InnoDB 백그라운드 쓰기 작업은 디스크의 전체 IOPS를 다 쓰면 안 되기 때문에 20~40% 정도만 잡습니다.

                100,000 × 0.02 ≈ 2000 → 이게 innodb_io_capacity의 시작점이 되는 이유.

                innodb_io_capacity_max는 순간적인 부하(체크포인트, Redo Log 꽉 참)에서 최대 허용 속도를 지정 → 평상시보다 2배 정도 크게 설정.

            4. 정리

                innodb_io_capacity = 2000 → 평상시 백그라운드 쓰기 속도 (SSD에 맞춘 안전한 값)

                innodb_io_capacity_max = 4000 → Flush가 몰릴 때 최대 속도 (배치 쓰기 순간 부하 완화)

                너무 낮으면 → 더티 페이지가 쌓여서 TPS가 떨어짐.
                너무 높으면 → 사용자 쿼리 I/O와 경합 → 읽기 지연 발생.

    더블라이트 버퍼: 최신 스토리지/엔진이면 기본값 유지(끄면 리스크 큼).

    Binlog: 레플리카/CDC 필요 시 binlog_format=ROW, binlog_row_image=MINIMAL로 쓰기량↓.


스키마/쿼리 측 최적화

    **current_viewers**는 JOIN 없는 단순 PK업서트 형태가 되도록 비정규화(현재/피크/오늘 고유 시청자 등 한 테이블).

    배치 쓰기 시 INSERT ... ON DUPLICATE KEY UPDATE 또는 MERGE(8.0.19+) 사용, 배치 크기 500~2,000행로 실측 최적값 탐색.

    파티션은 **히스토리 테이블(viewer_history, daily_statistics)**에만 적용 → 쓰기/삭제/백업 윈도우 관리가 쉬움.


검증 지표

    Buffer Pool Hit Ratio(>99%), Checkpoint Age, Redo Writes/s, fsync/s

    SHOW ENGINE INNODB STATUS\G의 log flushed/sec, pending writes 추세

    배치 윈도우 내 p95/p99 INSERT/UPSERT 지연과 TPS 안정성



4. Redis Cluster 샤딩 & 리플리카 — “핫 키 분산 + 읽기 확장”

    왜 이렇게 했나

        실시간 증감(INCR/DECR) 트래픽의 대부분이 상위 소수 스트림에 몰림(핫스팟).

        키를 샤드에 균등 분산해 단일 노드 락/CPU 병목을 피하고, 읽기는 **슬레이브(리드 리플리카)**로 분산.

    설계 포인트

        키 설계: view:{stream_id} 형태로 해시 태그 고정 → 같은 스트림의 관련 키를 같은 슬롯에 유지 가능.

        배치/랭킹 조회는 Replica에서 읽기(강한 일관성이 필요 없는 화면).

        장애: 마스터 장애 시 슬레이브 승격(Sentinel/Cluster 자동화).

        일관성: 쓰기 직후 강한 일관성이 필요한 API는 마스터에서 읽기 또는 WAIT(복제 확인) 사용.

        참고: 현재 아키텍처 다이어그램은 3 Master + 3 Slave = 총 6노드 구성으로 설명되어 있어. “12개 노드 균등 분산” 문구는 확장 시나리오로 이해하면 돼요(원리는 동일: 마스터 수가 늘수록 슬롯 분산이 더 촘촘해짐).


    모니터링

        per‑shard ops/sec, 큐 길이, eviction 여부, replication lag, top keys

        슬로우로그로 핫키/느린 명령 포착


            1. 왜 Redis Cluster를 쓰나?

                우리 시스템에서 실시간 시청자 수는 +1, -1 같은 숫자 증가/감소(INCR/DECR) 요청이 매우 많이 발생합니다.

                그런데 인기 방송 몇 개(소수의 stream_id)에 트래픽이 몰림 → 이걸 핫스팟(hot key) 현상이라고 함.

                한 Redis 노드가 이 키만 계속 처리하면, 그 노드 CPU·락에 병목이 생겨 성능이 떨어짐.

            2. 샤딩(Sharding)으로 병목 분산

                Redis Cluster는 데이터를 슬롯 단위로 나눠서 여러 마스터 노드에 분산 저장합니다.

                예:

                stream_id=101 → 마스터 1

                stream_id=202 → 마스터 2

                stream_id=303 → 마스터 3

                이렇게 하면 트래픽이 여러 서버로 나눠져서 CPU 부하와 락 경합이 분산됩니다.

            3. 키 설계 — view:{stream_id}

                Redis Cluster는 키의 해시 슬롯을 자동 계산해서 샤드에 배치합니다.

                {} 안의 문자열만을 해시 대상으로 삼는 해시 태그(hash tag) 기능이 있음.

                view:{12345} → 12345만 보고 슬롯을 결정.

                이렇게 하면 같은 방송(stream_id)의 여러 관련 키가 같은 샤드에 모이도록 강제 가능.

            4. 리플리카(Replica)로 읽기 확장

                각 마스터마다 **슬레이브(읽기 전용 노드)**를 둡니다.

                슬레이브는 마스터 데이터를 복제받아, **조회 요청(GET, MGET, ZRANGE 등)**을 대신 처리.

                예:

                마스터: INCR/DECR 등 쓰기 전용

                슬레이브: 랭킹 화면, 배치 조회 등 강한 일관성 안 필요한 읽기 처리

                이렇게 하면 읽기 부하도 분산되어 TPS 확장.

            5. 장애 대응

                마스터 장애 시 슬레이브를 자동 승격 (Sentinel 또는 Cluster 기능 사용)

                서비스 중단 시간을 최소화.

            6. 일관성 관련

                쓰기 직후 바로 읽어서 최신 값이 꼭 필요한 API → 마스터에서 읽기

                아니면 WAIT 명령으로 복제가 끝난 걸 확인하고 읽기.

            7. 모니터링 포인트

                per-shard ops/sec: 각 샤드 초당 처리량

                큐 길이: 명령 대기 길이 → 병목 감지

                eviction 여부: 메모리 부족으로 키가 강제 삭제되는지

                replication lag: 슬레이브 복제 지연

                top keys: 가장 많이 접근되는 키 → 핫스팟 탐지

                슬로우 로그: 느린 명령과 원인 파악


    Redis에 저장되는 구체 데이터 예시

            방송별 현재 시청자 수

                키: view:{stream_id}:current

                값: 현재 접속 중인 시청자 수 (INCR / DECR로 실시간 변동)

            방송별 최고 시청자 수

                키: view:{stream_id}:peak

                값: 방송 중 최고 동시 시청자 수

            방송별 누적 시청자 수

                키: view:{stream_id}:total

                값: 방송 시작 이후 누적 접속 인원

            선택적으로, 방송 참여자 목록(짧게 유지)

                예: 최근 1~2분 동안 입장한 사용자 ID Set

                키: view:{stream_id}:recent_users

                값: Redis Set 구조로 저장, TTL 적용


마무리: 변경이 진짜 효과 있었는지 “증명”하는 체크리스트

        FD/커넥션

            피크 시간 ESTAB 세션 수 = 목표 동접 대비 100%±x%

            accept 실패율/리트라이는 0에 수렴

        메모리/TCP

            커널 메모리 사용량(소켓 버퍼)이 설계치(≤1GB/50k) 근처로 줄었는지

            패킷 재전송률/RTT p99가 악화되지 않았는지

        MySQL

            배치 윈도우 동안 TPS/지연이 안정적, 체크포인트 스톨 없음

            리커버리 테스트에서 복구 시간이 허용 범위(redo 크기와 비례)

        Redis

            샤드 간 ops/sec 편차가 작고, 마스터 CPU/락 대기가 낮은지

            랭킹/조회 API의 p95 응답이 목표(예: <10ms) 충족